{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8615ecf-ac4f-4833-861f-c52d0e65da90",
   "metadata": {},
   "source": [
    "## FinTech 545 - Project Week 05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e383536-68d7-42a1-81f6-3becb4c0286e",
   "metadata": {},
   "source": [
    "## Renjie Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fb764-d5f9-4f48-aef2-67cf3aea8d0f",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616946b-01a6-4096-a983-2b3c503502c0",
   "metadata": {},
   "source": [
    "Covariance estimation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0607d26c-1b32-4738-bc4c-03e7a7fa6997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Function to calculate the covariance matrix for the dataframe that does not have the entire data.\n",
    "When skipRow is true, use all the rows which have values. When it's false, use pairwise.\n",
    "func can be np.cov (covariance) and np.corrcoef (correlation)\n",
    "'''\n",
    "def missing_cov_corr(df, skipRow=True, func=np.cov):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "    m, n = df.shape\n",
    "    missing_rows = df.isnull().any(axis=1).sum()\n",
    "\n",
    "    # If there is no missing rows, simply calculate the covariance matrix.\n",
    "    if not missing_rows:\n",
    "        cov = func(df.T)\n",
    "        print(cov)\n",
    "    else:\n",
    "        # skipRow is True, apply the method on the rows that have all the data.\n",
    "        if skipRow:\n",
    "            # Drop the rows that is not of whole data\n",
    "            df = df.dropna(axis=0, how='any')\n",
    "            cov = func(df.T)\n",
    "        # skipRow is True, apply the pairwise method.\n",
    "        else:\n",
    "            out = np.empty((n, n))\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1):\n",
    "                    # Select only rows without missing values in either column i or j\n",
    "                    valid_rows = df.iloc[:, [i, j]].dropna().index\n",
    "\n",
    "                    if not valid_rows.empty:\n",
    "                        cov_ij = func(df.iloc[valid_rows, [i, j]], rowvar=False)[0, 1]\n",
    "                        out[i, j] = cov_ij\n",
    "                        out[j, i] = cov_ij\n",
    "                        cov = out\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eaa8ae-d09d-46c0-b2c7-b0f4f823186d",
   "metadata": {},
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d6166b-ef78-432d-aa1f-5209401b2396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_1.1\n",
    "\n",
    "df = pd.read_csv('test1.csv')\n",
    "out1 = pd.read_csv('testout_1.1.csv')\n",
    "\n",
    "# Calculate covariance matrix skipping rows\n",
    "res1 = missing_cov_corr(df, skipRow=True, func=np.cov)\n",
    "close_elements = np.isclose(out1, res1, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 1.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653584ea-c6f4-4d56-b9f6-57ad3cde7792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_1.2\n",
    "\n",
    "out2 = pd.read_csv('testout_1.2.csv')\n",
    "\n",
    "# Calculate correlation matrix skipping rows\n",
    "res2 = missing_cov_corr(df, skipRow=True, func=np.corrcoef)\n",
    "close_elements = np.isclose(out2, res2, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 1.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa856d29-c59b-4b5b-8842-9eef882e9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_1.3\n",
    "\n",
    "out3 = pd.read_csv('testout_1.3.csv')\n",
    "\n",
    "# Calculate covariance matrix pairwise\n",
    "res3 = missing_cov_corr(df, skipRow=False, func=np.cov)\n",
    "close_elements = np.isclose(out3, res3, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 1.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d47751-a9fe-4a74-9eec-d91db02c8348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_1.4\n",
    "\n",
    "out4 = pd.read_csv('testout_1.4.csv')\n",
    "\n",
    "# Calculate covariance matrix pairwise\n",
    "res4 = missing_cov_corr(df, skipRow=False, func=np.corrcoef)\n",
    "close_elements = np.isclose(out4, res4, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 1.4 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eb0acc5-7455-4ac6-a921-da4223db6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function that calculates the EW covariance and correlation.\n",
    "Func take the parameter of 'cov' and 'corr'\n",
    "'''\n",
    "def ew_cov_corr(df, lmbd, func='cov'):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "        \n",
    "    if func not in ['cov', 'corr']:\n",
    "        raise ValueError(f'The func parameter must be \"cov\" or \"corr\", got {func} instead.')\n",
    "    \n",
    "    # Center the data - to calculate the covariance matrix.\n",
    "    df -= df.mean(axis=0)\n",
    "        \n",
    "    m, n = df.shape\n",
    "    wts = np.empty(m)\n",
    "    \n",
    "    # Setting weights for prior observation\n",
    "    for i in range(m):\n",
    "        wts[i] = (1 - lmbd) * lmbd ** (m - i - 1)\n",
    "        \n",
    "    # Normalizing the weights\n",
    "    wts /= np.sum(wts)\n",
    "    wts = wts.reshape(-1, 1)\n",
    "    if func == 'cov':   \n",
    "        res = (wts * df).T @ df\n",
    "        \n",
    "    elif func == 'corr':\n",
    "        res = (wts * df).T @ df\n",
    "        # Calculate the standard deviations (square root of variances along the diagonal)\n",
    "        std_devs = np.sqrt(np.diag(res))\n",
    "\n",
    "        # Convert the covariance matrix to a correlation matrix\n",
    "        res /= np.outer(std_devs, std_devs)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2729a0d-949a-4a25-8dd6-90a259d7d21d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_2.1\n",
    "df = pd.read_csv('test2.csv')\n",
    "\n",
    "out1 = pd.read_csv('testout_2.1.csv')\n",
    "res1 = ew_cov_corr(df, 0.97, func='cov')\n",
    "close_elements = np.isclose(out1, res1, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 2.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b25e0804-40c1-4581-a756-1746cc6d497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_2.2\n",
    "out2 = pd.read_csv('testout_2.2.csv')\n",
    "res2 = ew_cov_corr(df, 0.94, func='corr')\n",
    "close_elements = np.isclose(out2, res2, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 2.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd663e61-c56e-4cd7-918f-7e8d607182b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_2.3\n",
    "out3 = pd.read_csv('testout_2.3.csv')\n",
    "\n",
    "cov = ew_cov_corr(df, 0.97, func='cov')\n",
    "sd1 = np.sqrt(np.diag(cov))\n",
    "cov  = ew_cov_corr(df, 0.94, func='cov')\n",
    "sd = 1 / np.sqrt(np.diag(cov))\n",
    "res3 = np.diag(sd1) @ np.diag(sd) @ cov @ np.diag(sd) @ np.diag(sd1)\n",
    "\n",
    "close_elements = np.isclose(out3, res3, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 2.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ecaf3-8645-4ce1-a469-60bae157a026",
   "metadata": {},
   "source": [
    "Non-PSD fixes for correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a259a3-d523-42ae-a30e-daac4e48ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Near-PSD covariance and correlation.\n",
    "'''\n",
    "def near_psd(df, epsilon=0.0):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "\n",
    "    invSD = None\n",
    "\n",
    "    # If the matrix is the covariance matrix, convert it to correlation matrix first.\n",
    "    if not np.allclose(np.diag(df), 1.0, rtol=1e-03):\n",
    "        invSD = np.diag(1.0 / np.sqrt(np.diag(df)))\n",
    "        df = invSD @ df @ invSD\n",
    "        # # Calculate the standard deviations (square root of variances along the diagonal)\n",
    "        # std_devs = np.sqrt(np.diag(df))\n",
    "        # # Convert the covariance matrix to a correlation matrix\n",
    "        # df /= np.outer(std_devs, std_devs)\n",
    "    \n",
    "    # Calculate eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(df)\n",
    "    \n",
    "    # Update the negative eigenvalues to 0.\n",
    "    eigenvalues = np.maximum(eigenvalues, epsilon)\n",
    "    \n",
    "    # Construct the diagonal scaling matrix\n",
    "    S = 1 / (eigenvectors * eigenvectors @ eigenvalues)\n",
    "    S = np.diag(np.sqrt(S))\n",
    "    #T = np.diag(1.0 / np.sqrt(np.sum(eigenvectors**2 * eigenvalues, axis=0)))\n",
    "    l = np.diag(np.sqrt(eigenvalues))\n",
    "    B = S @ eigenvectors @ l\n",
    "    df = B @ B.T\n",
    "    \n",
    "    # Add back the variance\n",
    "    if invSD is not None:\n",
    "        invSD = np.diag(1 / np.diag(invSD))\n",
    "        df = invSD @ df @ invSD\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a10e950-f592-4693-93f8-4fdd3c759d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_3.1\n",
    "df = pd.read_csv('testout_1.3.csv')\n",
    "\n",
    "out1 = pd.read_csv('testout_3.1.csv')\n",
    "res1 = near_psd(df)\n",
    "close_elements = np.isclose(out1, res1, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 3.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492c67a2-3e51-4090-b805-dc6f11907fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_3.2\n",
    "df = pd.read_csv('testout_1.4.csv')\n",
    "\n",
    "out2 = pd.read_csv('testout_3.2.csv')\n",
    "res2 = near_psd(df)\n",
    "close_elements = np.isclose(out2, res2, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 3.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6221cd5-4786-4a3a-9954-6b5b5dc13fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Higham-PSD covariance and correlation.\n",
    "'''\n",
    "def higham_psd(df, W=None, epsilon=1e-9, maxIter=100, tol=1e-9):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "    \n",
    "    m, n = df.shape\n",
    "    \n",
    "    # Generate the identity matrix.\n",
    "    if W is None:\n",
    "        W = np.eye(m)\n",
    "        \n",
    "    deltaS = 0    \n",
    "    invSD = None\n",
    "    \n",
    "    Yk = np.copy(df)\n",
    "\n",
    "    # If the matrix is the covariance matrix, convert it to correlation matrix first.\n",
    "    if not np.allclose(np.diag(Yk), 1.0, rtol=1e-03):\n",
    "        invSD = np.diag(1.0 / np.sqrt(np.diag(Yk)))\n",
    "        Yk = invSD @ Yk @ invSD\n",
    "        \n",
    "    Yo = np.copy(Yk)\n",
    "    norml = np.finfo(np.float64).max\n",
    "    i = 1\n",
    "    \n",
    "    while i <= maxIter:\n",
    "        Rk = Yk - deltaS\n",
    "        \n",
    "        # Ps update\n",
    "        Xk = getPS(Rk, W)\n",
    "        deltaS = Xk - Rk\n",
    "        # Pu update\n",
    "        Yk = getPu(Xk)\n",
    "        # Get Norm\n",
    "        norm = wgtNorm(Yk-Yo, W)\n",
    "        #Smallest Eigenvalue\n",
    "        minEigVal = np.min(np.real(np.linalg.eigvals(Yk)))\n",
    "        \n",
    "        if norm - norml < tol and minEigVal > -epsilon:\n",
    "            break\n",
    "        \n",
    "        norml = norm\n",
    "        i += 1\n",
    "\n",
    "    if i < maxIter:\n",
    "        print(\"Converged in {} iterations.\".format(i))\n",
    "    else:\n",
    "        print(\"Convergence failed after {} iterations\".format(i-1))\n",
    "    \n",
    "    # Add back the variance\n",
    "    if invSD is not None:\n",
    "        invSD = np.diag(1 / np.diag(invSD))\n",
    "        Yk = invSD @ Yk @ invSD\n",
    "        \n",
    "    return Yk\n",
    "\n",
    "'''\n",
    "Helper functions\n",
    "'''\n",
    "def getAplus(A):\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "    eigenvalues = np.diag(np.maximum(eigenvalues, 0))\n",
    "    return eigenvectors @ eigenvalues @ eigenvectors.T\n",
    "\n",
    "def getPS(A, W):\n",
    "    W05 = np.sqrt(W)\n",
    "    iW = np.linalg.inv(W05)\n",
    "    return (iW @ getAplus(W05 @ A @ W05) @ iW)\n",
    "\n",
    "def getPu(A):\n",
    "    A = np.copy(A)  # Work on a copy to avoid modifying the original matrix\n",
    "    np.fill_diagonal(A, 1)\n",
    "    return A\n",
    "\n",
    "def wgtNorm(A, W):\n",
    "    W05 = np.sqrt(W)\n",
    "    W05 = W05 @ A @ W05\n",
    "    return np.sum(W05 * W05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34c0540-b136-45ea-a9d2-f95c37be4105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 20 iterations.\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_3.3\n",
    "df = pd.read_csv('testout_1.3.csv')\n",
    "\n",
    "out3 = pd.read_csv('testout_3.3.csv')\n",
    "res3 = higham_psd(df)\n",
    "close_elements = np.isclose(out3, res3, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 3.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83f0b821-e2f1-4c6d-a663-b1131513f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 1 iterations.\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_3.4\n",
    "df = pd.read_csv('testout_1.4.csv')\n",
    "\n",
    "out4 = pd.read_csv('testout_3.4.csv')\n",
    "res4 = higham_psd(df)\n",
    "close_elements = np.isclose(out4, res4, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 3.4 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77cf6fbd-557d-4896-b94f-0d8347e02381",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cholesky Factorization\n",
    "'''\n",
    "def chol_psd(df):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        df = pd.DataFrame(df)\n",
    "    \n",
    "    m, n = df.shape\n",
    "    root = np.zeros((m, n))  # Initialize the root matrix within the function\n",
    "    \n",
    "    for j in range(m):\n",
    "        s = 0.0\n",
    "        # If we are not on the first column, calculate the dot product of the preceeding row values.\n",
    "        if j >= 0:\n",
    "            s =  np.dot(root[j, :j], root[j, :j])\n",
    "            \n",
    "            # Diagonal element\n",
    "            temp = df.iloc[j, j] - s\n",
    "            if -1e-8 <= temp <= 0:\n",
    "                temp = 0.0\n",
    "            root[j, j] = np.sqrt(max(temp, 0))\n",
    "            \n",
    "            if root[j, j] == 0.0:\n",
    "                root[j, (j+1):n] = 0.0\n",
    "            else:\n",
    "                ir = 1.0 / root[j, j]\n",
    "                for i in range(j+1, m):\n",
    "                    s = np.dot(root[i, :j], root[j, :j])\n",
    "                    root[i, j] = (df.iloc[i, j] - s) * ir\n",
    "                    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f442d83-51f4-4bf8-bfd6-d32b76ba9123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_4.1\n",
    "df = pd.read_csv('testout_3.1.csv')\n",
    "\n",
    "out = pd.read_csv('testout_4.1.csv')\n",
    "res = chol_psd(df)\n",
    "close_elements = np.isclose(out, res, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 4.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c527dc-6621-429a-b4ee-1bf6427f4534",
   "metadata": {},
   "source": [
    "Simulation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd4b3f1b-080f-46ac-826b-f49ee15824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate Normal Simulation\n",
    "'''\n",
    "def simulateNormal(N, df, mean=None, seed=1234, fixMethod=near_psd):\n",
    "    # Error Checking\n",
    "    m, n = df.shape\n",
    "    if n != m:\n",
    "        raise ValueError(f\"Covariance Matrix is not square ({n},{m})\")\n",
    "    \n",
    "    # Initialize the output\n",
    "    out = np.zeros((N, n))\n",
    "    \n",
    "    # Set mean\n",
    "    if mean is None:\n",
    "        mean = np.zeros(n)\n",
    "    else:\n",
    "        if len(mean) != n:\n",
    "            raise ValueError(f\"Mean ({len(mean)}) is not the size of cov ({n},{n})\")\n",
    "    \n",
    "    # Set the seed to make sure the value is the same each time.\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(df)\n",
    "    # If the covariance is not PSD, try to fix it\n",
    "    if min(eigenvalues) < 0:\n",
    "        df = fixMethod(df)\n",
    "        \n",
    "    # Take the root (cholesky factorization)\n",
    "    l = chol_psd(df)\n",
    "    \n",
    "    # Generate random standard normals\n",
    "    rand_normals = np.random.normal(0.0, 1.0, size=(N, n))\n",
    "    \n",
    "    # Apply the Cholesky root and plus the mean to the random normals\n",
    "    out = np.dot(rand_normals, l.T) + mean\n",
    "    \n",
    "    return out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6118293-8371-4485-978e-9cb226753589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_5.1\n",
    "df = pd.read_csv('test5_1.csv')\n",
    "\n",
    "out = pd.read_csv('testout_5.1.csv')\n",
    "sim = simulateNormal(100000, df)\n",
    "res = np.cov(sim)\n",
    "\n",
    "# atol is the absolute tolerance parameter - set to a lower tolerance since the simulation is random.\n",
    "close_elements = np.isclose(out, res, atol=1e-3)\n",
    "\n",
    "\n",
    "# Test 5.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3afeaec0-9c3d-41db-9008-364a10c52bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_5.2\n",
    "df = pd.read_csv('test5_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout_5.2.csv')\n",
    "sim = simulateNormal(100000, df)\n",
    "res = np.cov(sim)\n",
    "\n",
    "# atol is the absolute tolerance parameter - set to a lower tolerance since the simulation is random.\n",
    "close_elements = np.isclose(out, res, atol=1e-3)\n",
    "\n",
    "\n",
    "# Test 5.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "630cacf8-c9c7-4fa7-9122-520fd48bbe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_5.3\n",
    "df = pd.read_csv('test5_3.csv')\n",
    "\n",
    "out = pd.read_csv('testout_5.3.csv')\n",
    "sim = simulateNormal(100000, df, fixMethod=near_psd)\n",
    "res = np.cov(sim)\n",
    "\n",
    "# atol is the absolute tolerance parameter - set to a lower tolerance since the simulation is random.\n",
    "close_elements = np.isclose(out, res, atol=1e-3)\n",
    "\n",
    "\n",
    "# Test 5.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87277133-af03-4009-9b03-ba28b8d852d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 16 iterations.\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_5.4\n",
    "df = pd.read_csv('test5_3.csv')\n",
    "\n",
    "out = pd.read_csv('testout_5.4.csv')\n",
    "sim = simulateNormal(100000, df, fixMethod=higham_psd)\n",
    "res = np.cov(sim)\n",
    "\n",
    "# atol is the absolute tolerance parameter - set to a lower tolerance since the simulation is random.\n",
    "close_elements = np.isclose(out, res, atol=1e-3)\n",
    "\n",
    "\n",
    "# Test 5.4 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68a22198-5109-47ac-b37a-7e26c8be9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multivariate PCA Simulation\n",
    "'''\n",
    "def simulatePCA(N, df, mean=None, seed=1234, pctExp=1):\n",
    "    # Error Checking\n",
    "    m, n = df.shape\n",
    "    if n != m:\n",
    "        raise ValueError(f\"Covariance Matrix is not square ({n},{m})\")\n",
    "    \n",
    "    # Initialize the output\n",
    "    out = np.zeros((N, n))\n",
    "    \n",
    "    # Set mean\n",
    "    if mean is None:\n",
    "        mean = np.zeros(n)\n",
    "    else:\n",
    "        if len(mean) != n:\n",
    "            raise ValueError(f\"Mean ({len(mean)}) is not the size of cov ({n},{n})\")\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(df)\n",
    "    \n",
    "    # Get the indices that would sort eigenvalues in descending order\n",
    "    indices = np.argsort(eigenvalues)[::-1]\n",
    "    # Sort eigenvalues\n",
    "    eigenvalues = eigenvalues[indices]\n",
    "    # Sort eigenvectors according to the same order\n",
    "    eigenvectors = eigenvectors[:, indices]\n",
    "    \n",
    "    tv = np.sum(eigenvalues)\n",
    "    posv = np.where(eigenvalues >= 1e-8)[0]\n",
    "    if pctExp <= 1:\n",
    "        nval = 0\n",
    "        pct = 0.0\n",
    "        # How many factors needed\n",
    "        for i in posv:\n",
    "            pct += eigenvalues[i] / tv\n",
    "            nval += 1\n",
    "            if pct >= pctExp:\n",
    "                break\n",
    "    \n",
    "     # If nval is less than the number of positive eigenvalues, truncate posv\n",
    "    if nval < len(posv):\n",
    "        posv = posv[:nval]\n",
    "        \n",
    "    # Filter eigenvalues based on posv\n",
    "    eigenvalues = eigenvalues[posv]\n",
    "    eigenvectors = eigenvectors[:, posv]\n",
    "    \n",
    "    B = eigenvectors @ np.diag(np.sqrt(eigenvalues))\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    rand_normals = np.random.normal(0.0, 1.0, size=(N, len(posv)))\n",
    "    out = np.dot(rand_normals, B.T) + mean\n",
    "    \n",
    "    return out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb5c59f1-26a0-4cd6-bf16-217cb48b8e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_5.5\n",
    "df = pd.read_csv('test5_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout_5.5.csv')\n",
    "sim = simulatePCA(100000, df, pctExp=0.99)\n",
    "res = np.cov(sim)\n",
    "\n",
    "# atol is the absolute tolerance parameter - set to a lower tolerance since the simulation is random.\n",
    "close_elements = np.isclose(out, res, atol=1e-3)\n",
    "\n",
    "\n",
    "# Test 5.5 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba41caa-ddd0-4eef-8f35-718a854b8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate Return\n",
    "'''\n",
    "\n",
    "# Implement the function to calculate the return\n",
    "def return_calculate(prices, method='ARS', dateColumn='Date'):\n",
    "    # Exclude the date column from the calculations\n",
    "    tickers = [col for col in prices.columns if col != dateColumn]\n",
    "    df = prices[tickers] # The dataframe is now with no date column.\n",
    "    \n",
    "    # Calculate the return using Classical Brownian Motion.\n",
    "    if method == 'CBM':\n",
    "        df = df.diff().dropna()\n",
    "    \n",
    "    # Calculate the return using Arithmetic Return System.\n",
    "    elif method == 'ARS':\n",
    "        df = (df - df.shift(1)) / df.shift(1)\n",
    "        df = df.dropna()\n",
    "        \n",
    "    # Calculate the return using Geometric Brownian Motion.\n",
    "    elif method == 'GBM':\n",
    "        df = np.log(df).diff().dropna()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"method: {method} must be in (\\\"CBM\\\",\\\"ARS\\\",\\\"GBM\\\")\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c95a1f-da3b-4375-8ab2-2ea4ba56d612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# testout_6.1\n",
    "df = pd.read_csv('test6.csv')\n",
    "\n",
    "out = pd.read_csv('test6_1.csv').drop('Date', axis=1)\n",
    "res = return_calculate(df, dateColumn='Date')\n",
    "\n",
    "close_elements = np.allclose(out, res, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 6.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9a48fff-337a-4036-beb0-afb5aed3b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# testout_6.2\n",
    "df = pd.read_csv('test6.csv')\n",
    "\n",
    "out = pd.read_csv('test6_2.csv').drop('Date', axis=1)\n",
    "res = return_calculate(df, method='GBM', dateColumn='Date')\n",
    "\n",
    "close_elements = np.allclose(out, res, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 6.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a7132c7-bc10-431a-8097-a38e5b92c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "'''\n",
    "Fit the Data with Normal Distribution\n",
    "'''\n",
    "def fit_normal(data):\n",
    "    # Fit the normal distribution to the data\n",
    "    mu, std = norm.fit(data)\n",
    "    return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7890209e-4466-47da-af0e-d5eca2757fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_7.1\n",
    "df = pd.read_csv('test7_1.csv')\n",
    "\n",
    "out = pd.read_csv('testout7_1.csv')\n",
    "res = fit_normal(df)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-3)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 7.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "370d1bcd-59fb-453b-8cbe-fe9165ddc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution\n",
    "'''\n",
    "def fit_general_t(data):\n",
    "    # Fit the t distribution to the data\n",
    "    nu, mu, sigma = t.fit(data)\n",
    "    return mu, sigma, nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c091f7a0-151f-421f-ba74-248832770570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_7.2\n",
    "df = pd.read_csv('test7_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout7_2.csv')\n",
    "res = fit_general_t(df)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-3)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 7.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aca3d9ca-cd56-4e31-bdc6-d4799807f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution - regression\n",
    "'''\n",
    "def fit_regression_t(df):\n",
    "    Y = df.iloc[:, -1]\n",
    "    X = df.iloc[:, :-1]\n",
    "    betas = MLE_t(X, Y)\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # Get the residuals.\n",
    "    e = Y - np.dot(X, betas)\n",
    "\n",
    "    params = t.fit(e)\n",
    "    out = {\"mu\": [params[1]], \n",
    "           \"sigma\": [params[2]], \n",
    "           \"nu\": [params[0]]}\n",
    "    for i in range(len(betas)):\n",
    "        out[\"B\" + str(i)] = betas[i]\n",
    "    out = pd.DataFrame(out)\n",
    "    out.rename(columns={'B0': 'Alpha'}, inplace=True)\n",
    "    return out\n",
    "\n",
    "# The objective negative log-likelihood function (need to be minimized).\n",
    "def MLE_t(X, Y):\n",
    "    X = sm.add_constant(X)\n",
    "    def ll_t(params):\n",
    "        nu, sigma = params[:2]\n",
    "        beta_MLE_t = params[2:]\n",
    "        epsilon = Y - np.dot(X, beta_MLE_t)\n",
    "        # Calculate the log-likelihood\n",
    "        log_likelihood = np.sum(t.logpdf(epsilon, df=nu, loc=mu, scale=sigma))\n",
    "        return -log_likelihood\n",
    "    \n",
    "    beta = np.zeros(X.shape[1])\n",
    "    nu, mu, sigma = 1, 0, np.std(Y - np.dot(X, beta))\n",
    "    params = np.append([nu, sigma], beta)\n",
    "    bnds = ((1e-9, None), (1e-9, None), (None, None), (None, None), (None, None), (None, None))\n",
    "    \n",
    "    # Minimize the log-likelihood to get the beta\n",
    "    res = minimize(ll_t, params, bounds=bnds, options={'disp': True})\n",
    "    beta_MLE = res.x[2:]\n",
    "    return beta_MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b7bc3e4-753c-4a77-9886-c6232f97b32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_7.3\n",
    "df = pd.read_csv('test7_3.csv')\n",
    "\n",
    "out = pd.read_csv('testout7_3.csv')\n",
    "res = fit_regression_t(df)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-3)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 7.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f43ff-fb5d-4e2a-bf00-82f29336c77f",
   "metadata": {},
   "source": [
    "VaR calculation methods (all discussed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08222fb6-ef1e-4e37-aa56-0fc114a10d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "'''\n",
    "Fit the Data with Normal Distribution\n",
    "'''\n",
    "def fit_normal(data):\n",
    "    # Fit the normal distribution to the data\n",
    "    mu, std = norm.fit(data)\n",
    "    return mu, std\n",
    "\n",
    "\n",
    "'''\n",
    "VaR for Normal Distribution\n",
    "'''\n",
    "\n",
    "def var_normal(data, alpha=0.05):\n",
    "    # Fit the data with normal distribution.\n",
    "    mu, std = fit_normal(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    VaR = -norm.ppf(alpha, mu, std)\n",
    "    \n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    VaR_diff = VaR + mu\n",
    "    \n",
    "    return pd.DataFrame({\"VaR Absolute\": [VaR], \n",
    "                         \"VaR Diff from Mean\": [VaR_diff]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a783f36-4bb1-47d0-aa2f-93306a7c3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.1\n",
    "df = pd.read_csv('test7_1.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_1.csv')\n",
    "\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = var_normal(df, 0.05)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-3)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.1 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7502e4b-6cde-41c3-b884-3f3c731928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution\n",
    "'''\n",
    "def fit_general_t(data):\n",
    "    # Fit the t distribution to the data\n",
    "    nu, mu, sigma = t.fit(data)\n",
    "    return mu, sigma, nu\n",
    "\n",
    "\n",
    "'''\n",
    "VaR for t Distribution\n",
    "''' \n",
    "def var_t(data, alpha=0.05):\n",
    "    # Fit the data with t distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    VaR = -t.ppf(alpha, nu, mu, sigma)\n",
    "\n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    VaR_diff = VaR + mu\n",
    "    \n",
    "    return pd.DataFrame({\"VaR Absolute\": [VaR], \n",
    "                         \"VaR Diff from Mean\": [VaR_diff]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb0bbdfd-5b81-45f2-b239-03244d3956ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.2\n",
    "df = pd.read_csv('test7_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_2.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = var_t(df, 0.05)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.2 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f0c706b-e071-4b1c-8214-9f438755db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution\n",
    "'''\n",
    "def fit_general_t(data):\n",
    "    # Fit the t distribution to the data\n",
    "    nu, mu, sigma = t.fit(data)\n",
    "    return mu, sigma, nu\n",
    "\n",
    "'''\n",
    "VaR for t Distribution simulation\n",
    "''' \n",
    "def var_simulation(data, alpha=0.05, size=10000):\n",
    "    # Fit the data with t distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Generate given size random numbers from a t-distribution\n",
    "    random_numbers = t.rvs(df=nu, loc=mu, scale=sigma, size=size)\n",
    "    \n",
    "    return var_t(random_numbers, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fd875b4-0972-4de2-8379-92767772e9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.3 - It depends - 10000 might be not enough\n",
    "df = pd.read_csv('test7_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_3.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = var_simulation(df, 0.05, 10000)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-2)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.3 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ab74a-a75a-472d-bcea-2f70af6c2ccd",
   "metadata": {},
   "source": [
    "ES calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a9dcc6f-ad16-4aa9-9f02-6901bb2db104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "\n",
    "'''\n",
    "Fit the Data with Normal Distribution\n",
    "'''\n",
    "def fit_normal(data):\n",
    "    # Fit the normal distribution to the data\n",
    "    mu, std = norm.fit(data)\n",
    "    return mu, std\n",
    "\n",
    "'''\n",
    "VaR for Normal Distribution\n",
    "'''\n",
    "\n",
    "def var_normal(data, alpha=0.05):\n",
    "    # Fit the data with normal distribution.\n",
    "    mu, std = fit_normal(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    VaR = -norm.ppf(alpha, mu, std)\n",
    "    \n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    VaR_diff = VaR + mu\n",
    "    \n",
    "    return pd.DataFrame({\"VaR Absolute\": [VaR], \n",
    "                         \"VaR Diff from Mean\": [VaR_diff]})\n",
    "\n",
    "'''\n",
    "ES for Normal Distribution\n",
    "'''\n",
    "\n",
    "def es_normal(data, alpha=0.05):\n",
    "    # Fit the data with normal distribution.\n",
    "    mu, std = fit_normal(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    res = var_normal(data, alpha)\n",
    "    VaR = res.iloc[0, 0]\n",
    "    \n",
    "    # Define the integrand function: x times the PDF of the distribution\n",
    "    def integrand(x, mu, std):\n",
    "        return x * norm.pdf(x, loc=mu, scale=std)\n",
    "    \n",
    "    # Calculate the ES\n",
    "    ES, _ = quad(lambda x: integrand(x, mu, std), -np.inf, -VaR)\n",
    "    ES /= -alpha\n",
    "    \n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    ES_diff = ES + mu\n",
    "    \n",
    "    return pd.DataFrame({\"ES Absolute\": [ES], \n",
    "                         \"ES Diff from Mean\": [ES_diff]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "847145ed-06ac-4207-a84b-df5127a67a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.4\n",
    "df = pd.read_csv('test7_1.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_4.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = es_normal(df, 0.05)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-3)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.4 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bdf63b4-2503-4085-a03b-c44648730175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "from scipy.integrate import quad\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution\n",
    "'''\n",
    "def fit_general_t(data):\n",
    "    # Fit the t distribution to the data\n",
    "    nu, mu, sigma = t.fit(data)\n",
    "    return mu, sigma, nu\n",
    "\n",
    "'''\n",
    "VaR for t Distribution\n",
    "''' \n",
    "def var_t(data, alpha=0.05):\n",
    "    # Fit the data with t distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    VaR = -t.ppf(alpha, nu, mu, sigma)\n",
    "\n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    VaR_diff = VaR + mu\n",
    "    \n",
    "    return pd.DataFrame({\"VaR Absolute\": [VaR], \n",
    "                         \"VaR Diff from Mean\": [VaR_diff]})\n",
    "\n",
    "'''\n",
    "ES for t Distribution\n",
    "'''\n",
    "\n",
    "def es_t(data, alpha=0.05):\n",
    "    # Fit the data with normal distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    res = var_t(data, alpha)\n",
    "    VaR = res.iloc[0, 0]\n",
    "    \n",
    "    # Define the integrand function: x times the PDF of the distribution\n",
    "    def integrand(x, mu, sigma, nu):\n",
    "        return x * t.pdf(x, df=nu, loc=mu, scale=sigma)\n",
    "    \n",
    "    # Calculate the ES\n",
    "    ES, _ = quad(lambda x: integrand(x, mu, sigma, nu), -np.inf, -VaR)\n",
    "    ES /= -alpha\n",
    "    \n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    ES_diff = ES + mu\n",
    "    \n",
    "    return pd.DataFrame({\"ES Absolute\": [ES], \n",
    "                         \"ES Diff from Mean\": [ES_diff]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d99598eb-cf00-4eba-b385-25b8aa387773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.5\n",
    "df = pd.read_csv('test7_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_5.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = es_t(df, 0.05)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-5)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.5 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ead75e58-7475-4a93-91c7-7497e85e5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "'''\n",
    "Fit the Data with t Distribution\n",
    "'''\n",
    "def fit_general_t(data):\n",
    "    # Fit the t distribution to the data\n",
    "    nu, mu, sigma = t.fit(data)\n",
    "    return mu, sigma, nu\n",
    "\n",
    "'''\n",
    "VaR for t Distribution\n",
    "''' \n",
    "def var_t(data, alpha=0.05):\n",
    "    # Fit the data with t distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Calculate the VaR\n",
    "    VaR = -t.ppf(alpha, nu, mu, sigma)\n",
    "\n",
    "    # Calculate the relative difference from the mean expected.\n",
    "    VaR_diff = VaR + mu\n",
    "    \n",
    "    return pd.DataFrame({\"VaR Absolute\": [VaR], \n",
    "                         \"VaR Diff from Mean\": [VaR_diff]})\n",
    "\n",
    "'''\n",
    "VaR for t Distribution simulation\n",
    "''' \n",
    "\n",
    "def es_simulation(data, alpha=0.05, size=10000):\n",
    "    # Fit the data with t distribution.\n",
    "    mu, sigma, nu = fit_general_t(data)\n",
    "    \n",
    "    # Generate given size random numbers from a t-distribution\n",
    "    random_numbers = t.rvs(df=nu, loc=mu, scale=sigma, size=size)\n",
    "    \n",
    "    return es_t(random_numbers, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c6f2dee9-45d3-4aba-87fb-0c7154caa95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# testout_8.6 - It depends - 10000 might be not enough\n",
    "df = pd.read_csv('test7_2.csv')\n",
    "\n",
    "out = pd.read_csv('testout8_6.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = es_simulation(df, 0.05)\n",
    "\n",
    "close_elements = np.isclose(out, res, atol=1e-2)  # atol is the absolute tolerance parameter\n",
    "\n",
    "# Test 8.6 is passed.\n",
    "print(close_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88b2b678-31bf-4c71-ae9d-70194e2a8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, t\n",
    "\n",
    "'''\n",
    "VaR/ES on 2 levels from simulated values - Copula\n",
    "'''\n",
    "\n",
    "def simulateCopula(portfolio, returns):\n",
    "    portfolio['CurrentValue'] = portfolio['Holding'] * portfolio['Starting Price']\n",
    "    models = {}\n",
    "    uniform = pd.DataFrame()\n",
    "    standard_normal = pd.DataFrame()\n",
    "    \n",
    "    for stock in returns.columns:\n",
    "        # If the distribution for the model is normal, fit the data with normal distribution.\n",
    "        if portfolio.loc[portfolio['Stock'] == stock, 'Distribution'].iloc[0] == 'Normal':\n",
    "            models[stock] = norm.fit(returns[stock])\n",
    "            mu, sigma = norm.fit(returns[stock])\n",
    "            \n",
    "            # Transform the observation vector into a uniform vector using CDF.\n",
    "            uniform[stock] = norm.cdf(returns[stock], loc=mu, scale=sigma)\n",
    "            \n",
    "            # Transform the uniform vector into a Standard Normal vector usig the normal quantile function.\n",
    "            standard_normal[stock] = norm.ppf(uniform[stock])\n",
    "            \n",
    "        # If the distribution for the model is t, fit the data with normal t.\n",
    "        elif portfolio.loc[portfolio['Stock'] == stock, 'Distribution'].iloc[0] == 'T':\n",
    "            models[stock] = t.fit(returns[stock])\n",
    "            nu, mu, sigma = t.fit(returns[stock])\n",
    "            \n",
    "            # Transform the observation vector into a uniform vector using CDF.\n",
    "            uniform[stock] = t.cdf(returns[stock], df=nu, loc=mu, scale=sigma)\n",
    "            \n",
    "            # Transform the uniform vector into a Standard Normal vector usig the normal quantile function.\n",
    "            standard_normal[stock] = norm.ppf(uniform[stock])\n",
    "        \n",
    "    # Calculate Spearman's correlation matrix\n",
    "    spearman_corr_matrix = standard_normal.corr(method='spearman')\n",
    "    \n",
    "    nSim = 100000\n",
    "    \n",
    "    # Use the PCA to simulate the multivariate normal.\n",
    "    np.random.seed(1234)\n",
    "    simulations = simulatePCA(nSim, spearman_corr_matrix)\n",
    "    simulations = pd.DataFrame(simulations.T, columns=[stock for stock in returns.columns])\n",
    "    \n",
    "    # Transform the simulations into uniform variables using standard normal CDF.\n",
    "    uni = norm.cdf(simulations)\n",
    "    uni = pd.DataFrame(uni, columns=[stock for stock in returns.columns])\n",
    "    \n",
    "    simulatedReturns = pd.DataFrame()\n",
    "    # Transform the uniform variables into the desired data using quantile.\n",
    "    for stock in returns.columns:\n",
    "        # If the distribution for the model is normal, use the quantile of the normal distribution.\n",
    "        if portfolio.loc[portfolio['Stock'] == stock, 'Distribution'].iloc[0] == 'Normal':\n",
    "            mu, sigma = models[stock]\n",
    "            simulatedReturns[stock] = norm.ppf(uni[stock], loc=mu, scale=sigma)\n",
    "            \n",
    "        # If the distribution for the model is t, use the quantile of the t distribution.\n",
    "        elif portfolio.loc[portfolio['Stock'] == stock, 'Distribution'].iloc[0] == 'T':\n",
    "            nu, mu, sigma = models[stock]\n",
    "            simulatedReturns[stock] = t.ppf(uni[stock], df=nu, loc=mu, scale=sigma)\n",
    "    \n",
    "    simulatedValue = pd.DataFrame()\n",
    "    pnl = pd.DataFrame()\n",
    "    # Calculate the daily prices for each stock\n",
    "    for stock in returns.columns:\n",
    "        currentValue = portfolio.loc[portfolio['Stock'] == stock, 'CurrentValue'].iloc[0]\n",
    "        simulatedValue[stock] = currentValue * (1 + simulatedReturns[stock])\n",
    "        pnl[stock] = simulatedValue[stock] - currentValue\n",
    "        \n",
    "    risk = pd.DataFrame(columns = [\"Stock\", \"VaR95\", \"ES95\", \"VaR95_Pct\", \"ES95_Pct\"])\n",
    "    w = pd.DataFrame()\n",
    "\n",
    "    for stock in pnl.columns:\n",
    "        i = risk.shape[0]\n",
    "        risk.loc[i, \"Stock\"] = stock\n",
    "        risk.loc[i, \"VaR95\"] = -np.percentile(pnl[stock], 5)\n",
    "        risk.loc[i, \"VaR95_Pct\"] = risk.loc[i, \"VaR95\"] / portfolio.loc[portfolio['Stock'] == stock, 'CurrentValue'].iloc[0]\n",
    "        risk.loc[i, \"ES95\"] = -pnl[stock][pnl[stock] <= -risk.loc[i, \"VaR95\"]].mean()\n",
    "        risk.loc[i, \"ES95_Pct\"] = risk.loc[i, \"ES95\"] / portfolio.loc[portfolio['Stock'] == stock, 'CurrentValue'].iloc[0]\n",
    "        \n",
    "        # Determine the weights for the two stock\n",
    "        w.at['Weight', stock] = portfolio.loc[portfolio['Stock'] == stock, 'CurrentValue'].iloc[0] / portfolio['CurrentValue'].sum()\n",
    "        \n",
    "    # Calculate the total pnl.\n",
    "    pnl['Total'] = 0\n",
    "    for stock in returns.columns:\n",
    "        pnl['Total'] += pnl[stock]\n",
    "    \n",
    "    i = risk.shape[0]\n",
    "    risk.loc[i, \"Stock\"] = 'Total'\n",
    "    risk.loc[i, \"VaR95\"] = -np.percentile(pnl['Total'], 5)\n",
    "    risk.loc[i, \"VaR95_Pct\"] = risk.loc[i, \"VaR95\"] / portfolio['CurrentValue'].sum()\n",
    "    risk.loc[i, \"ES95\"] = -pnl['Total'][pnl['Total'] <= -risk.loc[i, \"VaR95\"]].mean()\n",
    "    risk.loc[i, \"ES95_Pct\"] = risk.loc[i, \"ES95\"] / portfolio['CurrentValue'].sum()\n",
    "\n",
    "\n",
    "        \n",
    "#     w = w.loc['Weight']\n",
    "#     weightedPnl = w * pnl\n",
    "#     weightedPnl['Total'] = 0\n",
    "    \n",
    "#     # Calculate the total PnL for one day.\n",
    "#     for stock in returns.columns:\n",
    "#         weightedPnl['Total'] += weightedPnl[stock]\n",
    "\n",
    "#     # Calculate the portfolio's mean and standard deviation\n",
    "#     portfolioMean = weightedPnl['Total'].mean()\n",
    "#     portfolioStd = weightedPnl['Total'].std()\n",
    "    \n",
    "#     # Determine the risk measure for the whole portfolio\n",
    "#     i = risk.shape[0]\n",
    "#     risk.loc[i, \"Stock\"] = 'Total'\n",
    "#     risk.loc[i, \"VaR95\"] = -norm.ppf(0.05, portfolioMean, portfolioStd)\n",
    "#     risk.loc[i, \"VaR95_Pct\"] = -norm.ppf(0.05, portfolioMean, portfolioStd)risk.loc[i, \"VaR95\"] / portfolio['CurrentValue'].sum()\n",
    "#     risk.loc[i, \"ES95\"] = -weightedPnl['Total'][weightedPnl['Total'] <= -risk.loc[i, \"VaR95\"]].mean()\n",
    "#     risk.loc[i, \"ES95_Pct\"] = risk.loc[i, \"ES95\"] / portfolio['CurrentValue'].sum()\n",
    "        \n",
    "    return risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de276b9f-d011-4f42-bc9d-48d3697cd53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock       VaR95        ES95  VaR95_Pct  ES95_Pct\n",
      "0      A   94.460376  118.289371   0.047230  0.059145\n",
      "1      B  107.880427  151.218174   0.035960  0.050406\n",
      "2  Total  152.565684  199.704532   0.030513  0.039941\n",
      "\n",
      "   Stock       VaR95        ES95 VaR95_Pct  ES95_Pct\n",
      "0      A    93.98826  117.199357  0.046994    0.0586\n",
      "1      B  108.812034  152.088099  0.036271  0.050696\n",
      "2  Total  152.863228  200.235847  0.030573  0.040047\n"
     ]
    }
   ],
   "source": [
    "# testout_9.1\n",
    "df1 = pd.read_csv('test9_1_portfolio.csv')\n",
    "df2 = pd.read_csv('test9_1_returns.csv')\n",
    "\n",
    "out = pd.read_csv('testout9_1.csv')\n",
    "# Calculate the VaR at 5% quantile.\n",
    "res = simulateCopula(df1, df2)\n",
    "\n",
    "# Test 9.1 is passed - within appropriate range.\n",
    "print(f'{out}\\n')\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
